{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cocoy02/BT4012_AML-Fraud-Detection/blob/main/GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXids5mq8b5E",
        "outputId": "f0318977-de3b-4340-aa90-d4cb1109369a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79d7a225a750>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "torch.manual_seed(15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlrlGit4B5gY",
        "outputId": "377289e6-7701-4502-fdad-42a53d282150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5G2FFj88b5H"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FHxfeIZ8b5I"
      },
      "outputs": [],
      "source": [
        "df_classes = pd.read_csv(\"/content/drive/My Drive/BT4012 Team 8/Data/elliptic_txs_classes.csv\")\n",
        "df_edges = pd.read_csv(\"/content/drive/My Drive/BT4012 Team 8/Data/elliptic_txs_edgelist.csv\")\n",
        "df_features = pd.read_csv(\"/content/drive/My Drive/BT4012 Team 8/Data/elliptic_txs_features.csv\", header=None)\n",
        "df_features.columns = ['txId', 'time_step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]\n",
        "#df_features = pd.merge(df_features,df_classes,left_on=\"txId\",right_on=\"txId\",how='left')\n",
        "df_classes['class'] = df_classes['class'].apply(lambda x: '0' if x == \"unknown\" else x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cwYUyrc8b5J"
      },
      "source": [
        "# GCN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(classes,edgelist,features,start_ts,end_ts):\n",
        "  num_features = features.shape[1]\n",
        "  num_tx = features.shape[0]\n",
        "  total_tx = list(classes.index)\n",
        "\n",
        "  # select only the transactions which are labelled\n",
        "  labelled_classes = classes[classes['class'] != '0']\n",
        "  labelled_tx = list(labelled_classes.index)\n",
        "\n",
        "  # to calculate a list of adjacency matrices for the different timesteps\n",
        "\n",
        "  adj_mats = []\n",
        "  features_labelled_ts = []\n",
        "  classes_ts = []\n",
        "  num_ts = 49 # number of timestamps from the paper\n",
        "\n",
        "  for ts in range(start_ts, end_ts):\n",
        "      features_ts = features[features['time_step'] == ts+1]\n",
        "      tx_ts = list(features_ts.index)\n",
        "\n",
        "      labelled_tx_ts = [tx for tx in tx_ts if tx in set(labelled_tx)]\n",
        "\n",
        "      # adjacency matrix for all the transactions\n",
        "      # we will only fill in the transactions of this timestep which have labels and can be used for training\n",
        "      adj_mat = pd.DataFrame(np.zeros((num_tx, num_tx)), index = total_tx, columns = total_tx)\n",
        "\n",
        "      edgelist_labelled_ts = edgelist.loc[edgelist.index.intersection(labelled_tx_ts).unique()]\n",
        "      for i in range(edgelist_labelled_ts.shape[0]):\n",
        "          adj_mat.loc[edgelist_labelled_ts.index[i], edgelist_labelled_ts.iloc[i]['txId2']] = 1\n",
        "\n",
        "      adj_mat_ts = adj_mat.loc[labelled_tx_ts, labelled_tx_ts]\n",
        "      features_l_ts = features.loc[labelled_tx_ts]\n",
        "\n",
        "      adj_mats.append(adj_mat_ts)\n",
        "      features_labelled_ts.append(features_l_ts)\n",
        "      classes_ts.append(classes.loc[labelled_tx_ts])\n",
        "\n",
        "  return adj_mats, features_labelled_ts, classes_ts"
      ],
      "metadata": {
        "id": "EZ2Gbj_OpGlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_mats, features_labelled_ts, classes_ts = load_data(df_classes,df_edges,df_features,0,34)\n"
      ],
      "metadata": {
        "id": "RTuHk56V9a0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN"
      ],
      "metadata": {
        "id": "7jkP1cUrCuPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "\n",
        "class GraphConv(nn.Module):\n",
        "    def __init__(self, in_features, out_features, activation  = 'relu', skip = False, skip_in_features = None):\n",
        "        super(GraphConv, self).__init__()\n",
        "        self.W = torch.nn.Parameter(torch.DoubleTensor(in_features, out_features))\n",
        "        nn.init.xavier_uniform_(self.W)\n",
        "\n",
        "        self.set_act = False\n",
        "        if activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "            self.set_act = True\n",
        "        elif activation == 'softmax':\n",
        "            self.activation = nn.Softmax(dim = 1)\n",
        "            self.set_act = True\n",
        "        else:\n",
        "            self.set_act = False\n",
        "            raise ValueError(\"activations supported are 'relu' and 'softmax'\")\n",
        "\n",
        "        self.skip = skip\n",
        "        if self.skip:\n",
        "            if skip_in_features == None:\n",
        "                raise ValueError(\"pass input feature size of the skip connection\")\n",
        "            self.W_skip = torch.nn.Parameter(torch.DoubleTensor(skip_in_features, out_features))\n",
        "            nn.init.xavier_uniform_(self.W)\n",
        "\n",
        "    def forward(self, A, H_in, H_skip_in = None):\n",
        "        # A must be an n x n matrix as it is an adjacency matrix\n",
        "        # H is the input of the node embeddings, shape will n x in_features\n",
        "        self.A = A\n",
        "        self.H_in = H_in\n",
        "        A_ = torch.add(self.A, torch.eye(self.A.shape[0]).double())\n",
        "        D_ = torch.diag(A_.sum(1))\n",
        "        # since D_ is a diagonal matrix,\n",
        "        # its root will be the roots of the diagonal elements on the principle diagonal\n",
        "        # since A is an adjacency matrix, we are only dealing with positive values\n",
        "        # all roots will be real\n",
        "        D_root_inv = torch.inverse(torch.sqrt(D_))\n",
        "        A_norm = torch.mm(torch.mm(D_root_inv, A_), D_root_inv)\n",
        "        # shape of A_norm will be n x n\n",
        "\n",
        "        H_out = torch.mm(torch.mm(A_norm, H_in), self.W)\n",
        "        # shape of H_out will be n x out_features\n",
        "\n",
        "        if self.skip:\n",
        "            H_skip_out = torch.mm(H_skip_in, self.W_skip)\n",
        "            H_out = torch.add(H_out, H_skip_out)\n",
        "\n",
        "        if self.set_act:\n",
        "            H_out = self.activation(H_out)\n",
        "\n",
        "        return H_out"
      ],
      "metadata": {
        "id": "Zv7AZ5eDCwn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN 2 layers"
      ],
      "metadata": {
        "id": "mUlfyngFC0fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_2layer(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features, skip = False):\n",
        "        super(GCN_2layer, self).__init__()\n",
        "        self.skip = skip\n",
        "\n",
        "        self.gcl1 = GraphConv(in_features, hidden_features)\n",
        "\n",
        "        if self.skip:\n",
        "            self.gcl_skip = GraphConv(hidden_features, out_features, activation = 'softmax', skip = self.skip,\n",
        "                                  skip_in_features = in_features)\n",
        "        else:\n",
        "            self.gcl2 = GraphConv(hidden_features, out_features, activation = 'softmax')\n",
        "\n",
        "    def forward(self, A, X):\n",
        "        out = self.gcl1(A, X)\n",
        "        if self.skip:\n",
        "            out = self.gcl_skip(A, out, X)\n",
        "        else:\n",
        "            out = self.gcl2(A, out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "I56fo6GCC2Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 167\n",
        "num_classes = 2\n",
        "num_ts = 49\n",
        "epochs = 15\n",
        "lr = 0.001\n",
        "max_train_ts = 34\n",
        "train_ts = np.arange(max_train_ts)\n",
        "\n",
        "#adj_mats, features_labelled_ts, classes_ts = dataSet\n",
        "\n",
        "# 0 - illicit, 1 - licit\n",
        "labels_ts = []\n",
        "for c in classes_ts:\n",
        "    labels_ts.append(np.array(c['class'] == '2', dtype = np.long))\n",
        "\n",
        "gcn = GCN_2layer(num_features, 100, num_classes)\n",
        "train_loss = nn.CrossEntropyLoss(weight = torch.DoubleTensor([0.7, 0.3]))\n",
        "optimizer = torch.optim.Adam(gcn.parameters(), lr = lr)\n",
        "\n",
        "# Training\n",
        "\n",
        "for ts in train_ts:\n",
        "    A = torch.tensor(adj_mats[ts].values)\n",
        "    X = torch.tensor(features_labelled_ts[ts].values)\n",
        "    L = torch.tensor(labels_ts[ts], dtype = torch.long)\n",
        "    for ep in range(epochs):\n",
        "        t_start = time.time()\n",
        "\n",
        "        gcn.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = gcn(A, X)\n",
        "\n",
        "        loss = train_loss(out, L)\n",
        "        train_pred = out.max(1)[1].type_as(L)\n",
        "        acc = (train_pred.eq(L).double().sum())/L.shape[0]\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sys.stdout.write(\"\\r Epoch %d/%d Timestamp %d/%d training loss: %f training accuracy: %f Time: %s\"\n",
        "                         %(ep, epochs, ts, max_train_ts, loss, acc, time.time() - t_start)\n",
        "                        )\n",
        "\n",
        "torch.save(gcn.state_dict(), \"/content/drive/My Drive/BT4012 Team 8/modelDir\"+ \"gcn_weights.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9SF2UahC9k-",
        "outputId": "3cd2e682-7f80-4043-f622-74749bcdf0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch 14/15 Timestamp 33/34 training loss: 0.466245 training accuracy: 0.928155 Time: 0.11188364028930664"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "test_ts = np.arange(14)\n",
        "adj_mats, features_labelled_ts, classes_ts = load_data(df_classes,df_edges,df_features, 35, 49)\n",
        "\n",
        "# 0 - illicit, 1 - licit\n",
        "labels_ts = []\n",
        "for c in classes_ts:\n",
        "    labels_ts.append(np.array(c['class'] == '2', dtype = np.long))\n",
        "\n",
        "gcn = GCN_2layer(num_features, 100, num_classes)\n",
        "gcn.load_state_dict(torch.load(\"/content/drive/My Drive/BT4012 Team 8/modelDir\"+ \"gcn_weights.pth\"))\n",
        "\n",
        "# Testing\n",
        "test_accs = []\n",
        "test_precisions = []\n",
        "test_recalls = []\n",
        "test_f1s = []\n",
        "\n",
        "for ts in test_ts:\n",
        "    A = torch.tensor(adj_mats[ts].values)\n",
        "    X = torch.tensor(features_labelled_ts[ts].values)\n",
        "    L = torch.tensor(labels_ts[ts], dtype = torch.long)\n",
        "\n",
        "    gcn.eval()\n",
        "    test_out = gcn(A, X)\n",
        "\n",
        "    test_pred = test_out.max(1)[1].type_as(L)\n",
        "    t_acc = (test_pred.eq(L).double().sum())/L.shape[0]\n",
        "    test_accs.append(t_acc.item())\n",
        "    test_precisions.append(precision_score(L, test_pred))\n",
        "    test_recalls.append(recall_score(L, test_pred))\n",
        "    test_f1s.append(f1_score(L, test_pred))\n",
        "\n",
        "acc = np.array(test_accs).mean()\n",
        "prec = np.array(test_precisions).mean()\n",
        "rec = np.array(test_recalls).mean()\n",
        "f1 = np.array(test_f1s).mean()\n",
        "\n",
        "print(\"GCN - averaged accuracy: {}, precision: {}, recall: {}, f1: {}\".format(acc, prec, rec, f1))"
      ],
      "metadata": {
        "id": "ys1YO5VZDV3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaf126b-e3b4-4935-ca3b-53a7ad3c3207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN - averaged accuracy: 0.9371110767475882, precision: 0.9371110767475882, recall: 1.0, f1: 0.9669427201086112\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}